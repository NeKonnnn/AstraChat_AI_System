# Конфигурация astrachat Backend
# Теперь все модели работают через llm-svc микросервис

# Основные настройки приложения
app:
  name: "astrachat Backend"
  version: "1.0.0"
  description: "Backend service for astrachat with microservice architecture"
  debug: false

# Настройки сервера
server:
  host: "0.0.0.0"
  port: 8000
  log_level: "INFO"
  workers: 1

# Настройки CORS
# Примечание: allowed_origins теперь читаются из секции urls в коде
# Измените значения в секции urls, чтобы обновить все URL
cors:
  allowed_origins: []  # Используются значения из секции urls
  allow_credentials: true
  allow_methods: ["*"]
  allow_headers: ["*"]

# Настройки микросервисов
microservices:
  # LLM Service (включает LLM, Vosk, Silero, WhisperX, Diarization)
  llm_svc:
    enabled: true
    # Примечание: base_url и external_url теперь читаются из секции urls в коде
    # Измените значения в секции urls, чтобы обновить все URL
    base_url: ""  # Используется docker_llm_svc из секции urls
    external_url: ""  # Используется localhost_8001 из секции urls
    timeout: 300  # 5 минут таймаут
    retry_attempts: 3
    retry_delay: 1  # секунды между попытками
    
    # Настройки моделей LLM
    models:
      default: "qwen-coder-30b"
      fallback: "deepseek-coder-6.7b"
      auto_select: true  # Автоматический выбор модели
      
    # Настройки транскрипции (Vosk)
    transcription:
      enabled: true
      default_language: "ru"
      supported_languages: ["ru", "en"]
      max_file_size: 52428800  # 50MB
      
    # Настройки синтеза речи (Silero)
    tts:
      enabled: true
      default_language: "ru"
      default_speaker: "baya"
      supported_languages: ["ru", "en"]
      supported_speakers:
        ru: ["baya", "kseniya", "xenia", "eugene", "aidar"]
        en: ["v3_en"]
      max_text_length: 5000
      default_sample_rate: 48000
      
    # Настройки продвинутой транскрипции (WhisperX)
    whisperx:
      enabled: true
      default_language: "ru"
      supported_languages: ["ru", "en", "auto"]
      device: "auto"  # auto, cpu, cuda
      compute_type: "float16"  # float16, int8, int8_float16
      batch_size: 16
      max_file_size: 104857600  # 100MB
      
    # Настройки диаризации (разделение по спикерам)
    diarization:
      enabled: true
      min_speakers: 1
      max_speakers: 10
      min_duration: 1.0  # секунды
      max_file_size: 104857600  # 100MB
      device: "auto"  # auto, cpu, cuda

# Настройки памяти и истории
memory:
  enabled: true
  storage_type: "file"  # file, redis, database
  file_path: "/app/memory"
  max_history_length: 100
  auto_save: true
  save_interval: 30  # секунды

# Настройки агентов
agents:
  enabled: true
  default_agent: "general"
  available_agents:
    - "general"
    - "calculation"
    - "document"
    - "web_search"
    - "memory"
    - "mcp"
  
  # Настройки LangGraph оркестратора
  orchestrator:
    enabled: true
    max_iterations: 10
    timeout: 60  # секунды
    parallel_execution: false

# Настройки инструментов
tools:
  enabled: true
  available_tools:
    - "calculator"
    - "web_search"
    - "file_operations"
    - "memory_operations"
    - "mcp_tools"

# Настройки логирования
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "/app/logs/backend.log"
  max_size: 10485760  # 10MB
  backup_count: 5
  console: true

# Настройки безопасности
security:
  enabled: false  # Отключено для локальной разработки
  api_key: null
  api_key_header: "X-API-Key"
  rate_limiting:
    enabled: false
    requests_per_minute: 60

# Настройки мониторинга
monitoring:
  enabled: false
  health_check_interval: 30  # секунды
  metrics_enabled: false
  prometheus_port: 9091

# Настройки кэширования
caching:
  enabled: true
  type: "memory"  # memory, redis
  ttl: 300  # секунды
  max_size: 1000

# Настройки WebSocket
websocket:
  enabled: true
  ping_interval: 30  # секунды
  ping_timeout: 10  # секунды
  max_connections: 100

# Настройки файлов
files:
  upload_dir: "/app/uploads"
  max_file_size: 104857600  # 100MB
  allowed_extensions: [".txt", ".md", ".pdf", ".docx", ".wav", ".mp3", ".mp4", ".m4a", ".flac", ".ogg"]
  temp_dir: "/tmp/astrachat"

# Настройки для разработки
development:
  hot_reload: true
  debug_toolbar: false
  profiling: false
  mock_llm: false  # Использовать заглушку вместо реального LLM

# Пути к моделям и папкам
paths:
  # Пути к папкам с моделями (относительно корня проекта)
  whisperx_models_dir: "whisperx_models"
  diarize_models_dir: "diarize_models"
  
  # Названия моделей
  whisperx_base_model: "base"
  whisperx_small_model: "small"
  diarize_model: "pyannote/speaker-diarization-3.1"
  
  # Пути для других модулей
  model_path: "models"  # Путь к конкретной модели LLM
  memory_path: "memory"  # Путь к папке с памятью диалогов

# URL-адреса для использования в приложении
# Измените эти значения, чтобы обновить все URL во всем приложении
# Названия переменных нейтральные и не привязаны к localhost или конкретным IP
urls:
  # Frontend адреса
  frontend_port_1: "http://localhost:3000"
  frontend_port_1_ipv4: "http://127.0.0.1:3000"
  
  # Frontend альтернативный порт
  frontend_port_2: "http://localhost:3001"
  frontend_port_2_ipv4: "http://127.0.0.1:3001"
  
  # Frontend Vite dev server
  frontend_port_3: "http://localhost:5173"
  frontend_port_3_ipv4: "http://127.0.0.1:5173"
  
  # Backend адреса 
  backend_port_1: "http://localhost:8000"
  backend_port_1_ipv4: "http://127.0.0.1:8000"
  
  # LLM Service адреса
  llm_service_port: "http://localhost:8001"
  
  # Backend альтернативный порт 
  backend_port_2: "http://localhost:8080"
  backend_port_2_ipv4: "http://127.0.0.1:8080"
  
  # Docker внутренние адреса
  frontend_docker: "http://astrachat-frontend:3000"
  backend_docker: "http://astrachat-backend:8000"
  llm_service_docker: "http://llm-svc:8000"
