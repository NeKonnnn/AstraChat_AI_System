"""
LLM Client –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å llm-svc —Å–µ—Ä–≤–∏—Å–æ–º
–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å OpenAI API —á–µ—Ä–µ–∑ llm-svc
"""

import httpx
import json
import asyncio
import logging
from typing import List, Dict, Any, Optional, Callable, AsyncGenerator
from datetime import datetime
import io
import os

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
from config import get_config

logger = logging.getLogger(__name__)

class LLMClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å llm-svc API"""
    
    def __init__(self, base_url: Optional[str] = None, api_key: Optional[str] = None):
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        config = get_config()
        llm_svc_config = config.get("microservices", {}).get("llm_svc", {})
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º URL –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        if base_url is None:
            # –í Docker –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π URL, –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ - –≤–Ω–µ—à–Ω–∏–π
            if os.getenv("DOCKER_ENV") == "true":
                self.base_url = llm_svc_config.get("base_url", "http://llm-svc:8000").rstrip('/')
            else:
                self.base_url = llm_svc_config.get("external_url", "http://localhost:8001").rstrip('/')
        else:
            self.base_url = base_url.rstrip('/')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ–ø–µ—á–∞—Ç–∫–∏ –≤ URL (1lm –≤–º–µ—Å—Ç–æ llm)
        if "1lm-svc" in self.base_url or "11m-svc" in self.base_url:
            logger.error(f"–û–ë–ù–ê–†–£–ñ–ï–ù–ê –û–ü–ï–ß–ê–¢–ö–ê –í URL: {self.base_url}. –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ llm-svc")
            self.base_url = self.base_url.replace("1lm-svc", "llm-svc").replace("11m-svc", "llm-svc")
            logger.info(f"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π URL: {self.base_url}")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π URL –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        logger.info(f"LLMClient –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å base_url: {self.base_url}, DOCKER_ENV: {os.getenv('DOCKER_ENV')}")
            
        self.api_key = api_key
        self.timeout = llm_svc_config.get("timeout", 300.0)
        
    def _get_headers(self) -> Dict[str, str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤"""
        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json"
        }
        if self.api_key:
            headers["X-API-Key"] = self.api_key
        return headers
    
    async def health_check(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è llm-svc"""
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(
                    f"{self.base_url}/v1/health",
                    headers=self._get_headers()
                )
                response.raise_for_status()
                return response.json()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–¥–æ—Ä–æ–≤—å—è llm-svc: {e}")
            return {"status": "unhealthy", "error": str(e)}
    
    async def get_models(self) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(
                    f"{self.base_url}/v1/models",
                    headers=self._get_headers()
                )
                response.raise_for_status()
                data = response.json()
                return data.get("data", [])
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}")
            return []
    
    async def chat_completion(
        self,
        messages: List[Dict[str, str]],
        model: str = "qwen-coder-30b",
        temperature: float = 0.7,
        max_tokens: int = 1024,
        stream: bool = False
    ) -> Dict[str, Any]:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç–≤–µ—Ç–∞"""
        
        payload = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "stream": stream
        }
        
        try:
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                if stream:
                    # –ü–æ—Ç–æ–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
                    async with client.stream(
                        "POST",
                        f"{self.base_url}/v1/chat/completions",
                        headers={**self._get_headers(), "Accept": "text/event-stream"},
                        json=payload
                    ) as response:
                        response.raise_for_status()
                        return response
                else:
                    # –û–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å
                    response = await client.post(
                        f"{self.base_url}/v1/chat/completions",
                        headers=self._get_headers(),
                        json=payload
                    )
                    response.raise_for_status()
                    return response.json()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ llm-svc: {e}")
            raise
    
    async def transcribe_audio(
        self,
        audio_file: bytes,
        filename: str = "audio.wav",
        language: str = "ru"
    ) -> Dict[str, Any]:
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ Vosk"""
        try:
            files = {
                "file": (filename, io.BytesIO(audio_file), "audio/wav")
            }
            data = {
                "language": language
            }
            
            async with httpx.AsyncClient(timeout=300.0) as client:
                response = await client.post(
                    f"{self.base_url}/v1/transcribe",
                    files=files,
                    data=data,
                    headers={"Accept": "application/json"}
                )
                response.raise_for_status()
                return response.json()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")
            raise
    
    async def synthesize_speech(
        self,
        text: str,
        language: str = "auto",
        speaker: str = "baya",
        sample_rate: int = 48000,
        speech_rate: float = 1.0
    ) -> bytes:
        """–°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Silero"""
        try:
            data = {
                "text": text,
                "language": language,
                "speaker": speaker,
                "sample_rate": sample_rate,
                "speech_rate": speech_rate
            }
            
            async with httpx.AsyncClient(timeout=300.0) as client:
                response = await client.post(
                    f"{self.base_url}/v1/synthesize",
                    data=data,
                    headers={"Accept": "audio/wav"}
                )
                response.raise_for_status()
                return response.content
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏: {e}")
            raise
    
    async def get_transcription_health(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"""
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(
                    f"{self.base_url}/v1/transcription/health",
                    headers=self._get_headers()
                )
                response.raise_for_status()
                return response.json()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {e}")
            return {"status": "unhealthy", "error": str(e)}
    
    async def get_tts_health(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞ TTS"""
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(
                    f"{self.base_url}/v1/tts/health",
                    headers=self._get_headers()
                )
                response.raise_for_status()
                return response.json()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è TTS: {e}")
            return {"status": "unhealthy", "error": str(e)}
    
    async def transcribe_audio_whisperx(
        self,
        audio_file: bytes,
        filename: str = "audio.wav",
        language: str = "auto",
        compute_type: str = "float16",
        batch_size: int = 16
    ) -> Dict[str, Any]:
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ WhisperX"""
        try:
            files = {
                "file": (filename, io.BytesIO(audio_file), "audio/wav")
            }
            data = {
                "language": language,
                "compute_type": compute_type,
                "batch_size": batch_size
            }
            
            async with httpx.AsyncClient(timeout=300.0) as client:
                response = await client.post(
                    f"{self.base_url}/v1/whisperx/transcribe",
                    files=files,
                    data=data,
                    headers={"Accept": "application/json"}
                )
                response.raise_for_status()
                return response.json()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ WhisperX: {e}")
            raise
    
    async def diarize_audio(
        self,
        audio_file: bytes,
        filename: str = "audio.wav",
        min_speakers: int = 1,
        max_speakers: int = 10,
        min_duration: float = 1.0
    ) -> Dict[str, Any]:
        """–î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞"""
        try:
            files = {
                "file": (filename, io.BytesIO(audio_file), "audio/wav")
            }
            data = {
                "min_speakers": min_speakers,
                "max_speakers": max_speakers,
                "min_duration": min_duration
            }
            
            async with httpx.AsyncClient(timeout=300.0) as client:
                response = await client.post(
                    f"{self.base_url}/v1/diarize",
                    files=files,
                    data=data,
                    headers={"Accept": "application/json"}
                )
                response.raise_for_status()
                return response.json()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")
            raise
    
    async def reload_whisperx_models(self) -> Dict[str, Any]:
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π WhisperX"""
        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    f"{self.base_url}/v1/whisperx/reload",
                    headers={"Accept": "application/json"}
                )
                response.raise_for_status()
                return response.json()
        except httpx.ConnectError as e:
            error_msg = f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ llm-svc –ø–æ –∞–¥—Ä–µ—Å—É {self.base_url} –¥–ª—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π."
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ llm-svc: {error_msg}. –î–µ—Ç–∞–ª–∏: {e}")
            raise Exception(error_msg) from e
        except httpx.HTTPStatusError as e:
            error_msg = f"–û—à–∏–±–∫–∞ HTTP {e.response.status_code} –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–µ–π: {e.response.text}"
            logger.error(f"–û—à–∏–±–∫–∞ HTTP –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–µ–π: {error_msg}")
            raise Exception(error_msg) from e
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π WhisperX: {e}")
            raise
    
    async def transcribe_with_diarization(
        self,
        audio_file: bytes,
        filename: str = "audio.wav",
        language: str = "auto",
        min_speakers: int = 1,
        max_speakers: int = 10,
        min_duration: float = 1.0
    ) -> Dict[str, Any]:
        """–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Å –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–µ–π"""
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            data = {
                "language": language,
                "min_speakers": min_speakers,
                "max_speakers": max_speakers,
                "min_duration": min_duration
            }
            
            async with httpx.AsyncClient(timeout=300.0) as client:
                # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
                files = {
                    "file": (filename, io.BytesIO(audio_file), "audio/wav")
                }
                
                response = await client.post(
                    f"{self.base_url}/v1/transcribe_with_diarization",
                    files=files,
                    data=data,
                    headers={"Accept": "application/json"}
                )
                
                # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –æ—à–∏–±–∫—É 503 —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º –æ –Ω–µ–∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö, –ø—ã—Ç–∞–µ–º—Å—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å
                if response.status_code == 503:
                    response_text = response.text
                    if "–ú–æ–¥–µ–ª–∏ WhisperX –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã" in response_text or "WhisperX models not loaded" in response_text:
                        logger.warning("–ú–æ–¥–µ–ª–∏ WhisperX –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –ø—ã—Ç–∞–µ–º—Å—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å...")
                        try:
                            await self.reload_whisperx_models()
                            logger.info("–ú–æ–¥–µ–ª–∏ WhisperX –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω—ã, –ø–æ–≤—Ç–æ—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏...")
                            # –ü–æ–≤—Ç–æ—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏ (—Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π BytesIO)
                            files_retry = {
                                "file": (filename, io.BytesIO(audio_file), "audio/wav")
                            }
                            response = await client.post(
                                f"{self.base_url}/v1/transcribe_with_diarization",
                                files=files_retry,
                                data=data,
                                headers={"Accept": "application/json"}
                            )
                        except Exception as reload_error:
                            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏ WhisperX: {reload_error}")
                            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –∏—Å—Ö–æ–¥–Ω–æ–π –æ—à–∏–±–∫–æ–π
                
                response.raise_for_status()
                return response.json()
        except httpx.ConnectError as e:
            error_msg = f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ llm-svc –ø–æ –∞–¥—Ä–µ—Å—É {self.base_url}. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–µ—Ä–≤–∏—Å –∑–∞–ø—É—â–µ–Ω –∏ –¥–æ—Å—Ç—É–ø–µ–Ω."
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ llm-svc: {error_msg}. –î–µ—Ç–∞–ª–∏: {e}")
            raise Exception(error_msg) from e
        except httpx.HTTPStatusError as e:
            error_msg = f"–û—à–∏–±–∫–∞ HTTP {e.response.status_code} –æ—Ç llm-svc: {e.response.text}"
            logger.error(f"–û—à–∏–±–∫–∞ HTTP –æ—Ç llm-svc: {error_msg}")
            raise Exception(error_msg) from e
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            raise
    
    async def recognize_text_from_image(
        self,
        image_file: bytes,
        filename: str = "image.jpg",
        languages: str = "ru,en"
    ) -> Dict[str, Any]:
        """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Surya OCR"""
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º MIME —Ç–∏–ø –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–∞
            mime_type = "image/jpeg"
            if filename.lower().endswith(".png"):
                mime_type = "image/png"
            elif filename.lower().endswith(".webp"):
                mime_type = "image/webp"
            elif filename.lower().endswith(".bmp"):
                mime_type = "image/bmp"
            elif filename.lower().endswith(".tiff") or filename.lower().endswith(".tif"):
                mime_type = "image/tiff"
            
            files = {
                "file": (filename, io.BytesIO(image_file), mime_type)
            }
            data = {
                "languages": languages
            }
            
            async with httpx.AsyncClient(timeout=300.0) as client:
                response = await client.post(
                    f"{self.base_url}/v1/ocr",
                    files=files,
                    data=data,
                    headers={"Accept": "application/json"}
                )
                response.raise_for_status()
                return response.json()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            raise
    
    async def get_ocr_health(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞ OCR"""
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(
                    f"{self.base_url}/v1/ocr/health",
                    headers=self._get_headers()
                )
                response.raise_for_status()
                return response.json()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è OCR: {e}")
            return {"status": "unhealthy", "error": str(e)}

class LLMService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å LLM —á–µ—Ä–µ–∑ llm-svc"""
    
    def __init__(self, base_url: Optional[str] = None, api_key: Optional[str] = None):
        self.client = LLMClient(base_url, api_key)
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        config = get_config()
        llm_svc_config = config.get("microservices", {}).get("llm_svc", {})
        models_config = llm_svc_config.get("models", {})
        
        self.model_name = models_config.get("default", "qwen-coder-30b")
        self.fallback_model = models_config.get("fallback", "deepseek-coder-6.7b")
        self.auto_select = models_config.get("auto_select", True)
        
    async def initialize(self) -> bool:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞"""
        try:
            health = await self.client.health_check()
            if health.get("status") == "healthy":
                logger.info("llm-svc —Å–µ—Ä–≤–∏—Å –¥–æ—Å—Ç—É–ø–µ–Ω")
                
                # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
                models = await self.client.get_models()
                if models:
                    self.model_name = models[0]["id"]
                    logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å: {self.model_name}")
                
                return True
            else:
                logger.error(f"llm-svc –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {health}")
                return False
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ llm-svc: {e}")
            return False
    
    def prepare_messages(self, prompt: str, history: Optional[List[Dict[str, str]]] = None, 
                        system_prompt: Optional[str] = None) -> List[Dict[str, str]]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI API"""
        messages = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        elif history and len(history) > 0:
            # –ï—Å–ª–∏ –Ω–µ—Ç custom –ø—Ä–æ–º–ø—Ç–∞, –Ω–æ –µ—Å—Ç—å –∏—Å—Ç–æ—Ä–∏—è - –¥–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∏—Å—Ç–æ—Ä–∏–∏
            system_prompt_with_history = """–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –£ —Ç–µ–±—è –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ –ø–æ–ª–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞ —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.       
            –í–∞–∂–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
            - –¢—ã –ú–û–ñ–ï–®–¨ –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Å–æ–æ–±—â–µ–Ω–∏—è–º –≤ –¥–∏–∞–ª–æ–≥–µ
            - –¢—ã –ú–û–ñ–ï–®–¨ –ø–æ–¥—Å—á–∏—Ç–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –∏ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –∏—Å—Ç–æ—Ä–∏–∏
            - –¢—ã –í–ò–î–ò–®–¨ –≤—Å–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —ç—Ç–æ–º –¥–∏–∞–ª–æ–≥–µ
            - –¢—ã –ú–û–ñ–ï–®–¨ —Å—Å—ã–ª–∞—Ç—å—Å—è –Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π

            –ö–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏—è—Ö –∏–ª–∏ —Ç–æ–∫–µ–Ω–∞—Ö - –∏—Å–ø–æ–ª—å–∑—É–π –¥–æ—Å—Ç—É–ø–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–∞."""
            messages.append({"role": "system", "content": system_prompt_with_history})
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞
        if history:
            for entry in history:
                role = entry.get("role", "user")
                content = entry.get("content", "")
                if role in ["user", "assistant", "system"]:
                    messages.append({"role": role, "content": content})
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å
        messages.append({"role": "user", "content": prompt})
        
        return messages
    
    async def generate_response(
        self,
        prompt: str,
        history: Optional[List[Dict[str, str]]] = None,
        system_prompt: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: int = 1024,
        streaming: bool = False,
        stream_callback: Optional[Callable[[str, str], bool]] = None,
        images: Optional[List[str]] = None,
        model_path: Optional[str] = None
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ llm-svc"""
        
        try:
            # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å—Ç–æ—Ä–∏–∏
            if history:
                logger.info(f"üìö –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞: {len(history)} —Å–æ–æ–±—â–µ–Ω–∏–π –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –≤ LLM")
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ (–≥—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞: ~1 —Ç–æ–∫–µ–Ω = 4 —Å–∏–º–≤–æ–ª–∞ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ)
                total_chars = sum(len(msg.get("content", "")) for msg in history)
                estimated_tokens = total_chars // 4
                logger.info(f"üìä –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∏—Å—Ç–æ—Ä–∏–∏: {estimated_tokens}")
            else:
                logger.info("‚ö†Ô∏è –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–∞")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
            messages = self.prepare_messages(prompt, history, system_prompt)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º—ã—Ö –≤ LLM
            logger.info(f"üí¨ –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è LLM: {len(messages)} (–≤–∫–ª—é—á–∞—è system prompt –∏ —Ç–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å)")
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –¥–æ–±–∞–≤–ª—è–µ–º –∏—Ö –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É —Å–æ–æ–±—â–µ–Ω–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            if images:
                logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∫ –∑–∞–ø—Ä–æ—Å—É")
                # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                for msg in reversed(messages):
                    if msg.get("role") == "user":
                        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                        content = msg.get("content", "")
                        msg["content"] = [
                            {"type": "text", "text": content}
                        ]
                        # –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                        for image_path in images:
                            msg["content"].append({
                                "type": "image_url",
                                "image_url": {"url": f"file://{image_path}"}
                            })
                        break
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            if model_path and model_path.startswith("llm-svc://"):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –º–æ–¥–µ–ª–∏ –∏–∑ –ø—É—Ç–∏ llm-svc://
                model_to_use = model_path.replace("llm-svc://", "")
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏–ª–∏ –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                model_to_use = self.model_name
            
            if streaming and stream_callback:
                # –ü–æ—Ç–æ–∫–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
                return await self._stream_generation(
                    messages, temperature, max_tokens, stream_callback, model_to_use
                )
            else:
                # –û–±—ã—á–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
                response = await self.client.chat_completion(
                    messages=messages,
                    model=model_to_use,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    stream=False
                )
                
                if "choices" in response and len(response["choices"]) > 0:
                    return response["choices"][0]["message"]["content"]
                else:
                    logger.error("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç llm-svc")
                    return "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞"
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            return f"–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}"
    
    async def _stream_generation(
        self,
        messages: List[Dict[str, str]],
        temperature: float,
        max_tokens: int,
        stream_callback: Callable[[str, str], bool],
        model_name: Optional[str] = None
    ) -> str:
        """–ü–æ—Ç–æ–∫–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∫–æ–ª–±—ç–∫–æ–º"""
        
        accumulated_text = ""
        
        try:
            async with httpx.AsyncClient(timeout=self.client.timeout) as http_client:
                async with http_client.stream(
                    "POST",
                    f"{self.client.base_url}/v1/chat/completions",
                    headers={**self.client._get_headers(), "Accept": "text/event-stream"},
                    json={
                        "model": model_name or self.model_name,
                        "messages": messages,
                        "temperature": temperature,
                        "max_tokens": max_tokens,
                        "stream": True
                    }
                ) as response:
                    response.raise_for_status()
                    
                    async for line in response.aiter_lines():
                        if line.startswith("data: "):
                            data_str = line[6:]  # –£–±–∏—Ä–∞–µ–º "data: "
                            
                            if data_str.strip() == "[DONE]":
                                break
                            
                            try:
                                data = json.loads(data_str)
                                if "choices" in data and len(data["choices"]) > 0:
                                    delta = data["choices"][0].get("delta", {})
                                    if "content" in delta:
                                        chunk = delta["content"]
                                        accumulated_text += chunk
                                        
                                        # –í—ã–∑—ã–≤–∞–µ–º –∫–æ–ª–±—ç–∫
                                        should_continue = stream_callback(chunk, accumulated_text)
                                        if not should_continue:
                                            logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ —Å–∏–≥–Ω–∞–ª—É –∫–æ–ª–±—ç–∫–∞")
                                            return None
                            except json.JSONDecodeError:
                                continue
                    
                    return accumulated_text
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ—Ç–æ–∫–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            return f"–û—à–∏–±–∫–∞ –ø–æ—Ç–æ–∫–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {str(e)}"
    
    async def transcribe_audio(
        self,
        audio_file: bytes,
        filename: str = "audio.wav",
        language: str = "ru"
    ) -> str:
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞"""
        try:
            result = await self.client.transcribe_audio(audio_file, filename, language)
            if result.get("success"):
                return result.get("text", "")
            else:
                logger.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏: {result.get('error', 'Unknown error')}")
                return ""
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")
            return ""
    
    async def synthesize_speech(
        self,
        text: str,
        language: str = "auto",
        speaker: str = "baya",
        sample_rate: int = 48000,
        speech_rate: float = 1.0
    ) -> bytes:
        """–°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        try:
            return await self.client.synthesize_speech(
                text, language, speaker, sample_rate, speech_rate
            )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏: {e}")
            return b""
    
    async def transcribe_audio_whisperx(
        self,
        audio_file: bytes,
        filename: str = "audio.wav",
        language: str = "auto",
        compute_type: str = "float16",
        batch_size: int = 16
    ) -> str:
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ WhisperX"""
        try:
            result = await self.client.transcribe_audio_whisperx(
                audio_file, filename, language, compute_type, batch_size
            )
            if result.get("success"):
                return result.get("text", "")
            else:
                logger.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ WhisperX: {result.get('error', 'Unknown error')}")
                return ""
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ WhisperX: {e}")
            return ""
    
    async def diarize_audio(
        self,
        audio_file: bytes,
        filename: str = "audio.wav",
        min_speakers: int = 1,
        max_speakers: int = 10,
        min_duration: float = 1.0
    ) -> Dict[str, Any]:
        """–î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞"""
        try:
            return await self.client.diarize_audio(
                audio_file, filename, min_speakers, max_speakers, min_duration
            )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")
            return {"success": False, "error": str(e)}
    
    async def transcribe_with_diarization(
        self,
        audio_file: bytes,
        filename: str = "audio.wav",
        language: str = "auto",
        min_speakers: int = 1,
        max_speakers: int = 10,
        min_duration: float = 1.0
    ) -> Dict[str, Any]:
        """–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Å –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–µ–π"""
        try:
            return await self.client.transcribe_with_diarization(
                audio_file, filename, language, min_speakers, max_speakers, min_duration
            )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            return {"success": False, "error": str(e)}
    
    async def recognize_text_from_image(
        self,
        image_file: bytes,
        filename: str = "image.jpg",
        languages: str = "ru,en"
    ) -> Dict[str, Any]:
        """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            return await self.client.recognize_text_from_image(image_file, filename, languages)
        except httpx.HTTPStatusError as e:
            error_detail = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"
            try:
                error_response = e.response.json()
                error_detail = error_response.get("detail", str(e))
            except:
                error_detail = str(e)
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (HTTP {e.response.status_code}): {error_detail}")
            return {"success": False, "error": error_detail}
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return {"success": False, "error": str(e)}
    
    async def get_audio_services_health(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∞—É–¥–∏–æ —Å–µ—Ä–≤–∏—Å–æ–≤"""
        try:
            transcription_health = await self.client.get_transcription_health()
            tts_health = await self.client.get_tts_health()
            
            return {
                "transcription": transcription_health,
                "tts": tts_health,
                "overall": "healthy" if (
                    transcription_health.get("status") == "healthy" and 
                    tts_health.get("status") == "healthy"
                ) else "unhealthy"
            }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∞—É–¥–∏–æ —Å–µ—Ä–≤–∏—Å–æ–≤: {e}")
            return {"overall": "unhealthy", "error": str(e)}

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
llm_service = None

async def get_llm_service() -> LLMService:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ LLM —Å–µ—Ä–≤–∏—Å–∞"""
    global llm_service
    if llm_service is None:
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        config = get_config()
        llm_svc_config = config.get("microservices", {}).get("llm_svc", {})
        
        base_url = None  # –ë—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –≤ LLMService
        api_key = None  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –≤ –∫–æ–Ω—Ñ–∏–≥ –≤ –±—É–¥—É—â–µ–º
        
        llm_service = LLMService(base_url, api_key)
        await llm_service.initialize()
    
    return llm_service

# –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –æ–±–µ—Ä—Ç–∫–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –∫–æ–¥–æ–º
def ask_agent_llm_svc(prompt: str, history: Optional[List[Dict[str, str]]] = None, 
                     max_tokens: Optional[int] = None, streaming: bool = False,
                     stream_callback: Optional[Callable[[str, str], bool]] = None,
                     model_path: Optional[str] = None, custom_prompt_id: Optional[str] = None,
                     images: Optional[List[str]] = None) -> str:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è ask_agent —á–µ—Ä–µ–∑ llm-svc"""
    
    async def _async_generate():
        service = await get_llm_service()
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –º–æ–¥–µ–ª–∏ –∏–∑ model_path, –µ—Å–ª–∏ –æ–Ω –ø–µ—Ä–µ–¥–∞–Ω
        model_name_for_request = None
        if model_path and model_path.startswith("llm-svc://"):
            model_name_for_request = model_path.replace("llm-svc://", "")
        
        return await service.generate_response(
            prompt=prompt,
            history=history,
            system_prompt=None,  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∫—É custom_prompt_id
            temperature=0.7,
            max_tokens=max_tokens or 1024,
            streaming=streaming,
            stream_callback=stream_callback,
            images=images,
            model_path=model_path if model_path and model_path.startswith("llm-svc://") else None
        )
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –≤ –Ω–æ–≤–æ–º event loop
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            # –ï—Å–ª–∏ loop —É–∂–µ –∑–∞–ø—É—â–µ–Ω, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(asyncio.run, _async_generate())
                return future.result()
        else:
            return loop.run_until_complete(_async_generate())
    except RuntimeError:
        # –ï—Å–ª–∏ –Ω–µ—Ç event loop, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
        return asyncio.run(_async_generate())

# –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –æ–±–µ—Ä—Ç–∫–∏ –¥–ª—è –∞—É–¥–∏–æ —Ñ—É–Ω–∫—Ü–∏–π
def transcribe_audio_llm_svc(audio_file: bytes, filename: str = "audio.wav", language: str = "ru") -> str:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ llm-svc"""
    
    async def _async_transcribe():
        service = await get_llm_service()
        return await service.transcribe_audio(audio_file, filename, language)
    
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(asyncio.run, _async_transcribe())
                return future.result()
        else:
            return loop.run_until_complete(_async_transcribe())
    except RuntimeError:
        return asyncio.run(_async_transcribe())

def synthesize_speech_llm_svc(text: str, language: str = "auto", speaker: str = "baya", 
                             sample_rate: int = 48000, speech_rate: float = 1.0) -> bytes:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ llm-svc"""
    
    async def _async_synthesize():
        service = await get_llm_service()
        return await service.synthesize_speech(text, language, speaker, sample_rate, speech_rate)
    
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(asyncio.run, _async_synthesize())
                return future.result()
        else:
            return loop.run_until_complete(_async_synthesize())
    except RuntimeError:
        return asyncio.run(_async_synthesize())

def transcribe_audio_whisperx_llm_svc(audio_file: bytes, filename: str = "audio.wav", 
                                     language: str = "auto", compute_type: str = "float16", 
                                     batch_size: int = 16) -> str:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ WhisperX —á–µ—Ä–µ–∑ llm-svc"""
    
    async def _async_transcribe():
        service = await get_llm_service()
        return await service.transcribe_audio_whisperx(audio_file, filename, language, compute_type, batch_size)
    
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(asyncio.run, _async_transcribe())
                return future.result()
        else:
            return loop.run_until_complete(_async_transcribe())
    except RuntimeError:
        return asyncio.run(_async_transcribe())

def diarize_audio_llm_svc(audio_file: bytes, filename: str = "audio.wav", 
                         min_speakers: int = 1, max_speakers: int = 10, 
                         min_duration: float = 1.0) -> Dict[str, Any]:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ llm-svc"""
    
    async def _async_diarize():
        service = await get_llm_service()
        return await service.diarize_audio(audio_file, filename, min_speakers, max_speakers, min_duration)
    
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(asyncio.run, _async_diarize())
                return future.result()
        else:
            return loop.run_until_complete(_async_diarize())
    except RuntimeError:
        return asyncio.run(_async_diarize())

def transcribe_with_diarization_llm_svc(audio_file: bytes, filename: str = "audio.wav", 
                                       language: str = "auto", min_speakers: int = 1, 
                                       max_speakers: int = 10, min_duration: float = 1.0) -> Dict[str, Any]:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–µ—Ä–µ–∑ llm-svc"""
    
    async def _async_transcribe_diarize():
        service = await get_llm_service()
        return await service.transcribe_with_diarization(
            audio_file, filename, language, min_speakers, max_speakers, min_duration
        )
    
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(asyncio.run, _async_transcribe_diarize())
                return future.result()
        else:
            return loop.run_until_complete(_async_transcribe_diarize())
    except RuntimeError:
        return asyncio.run(_async_transcribe_diarize())

def recognize_text_from_image_llm_svc(image_file: bytes, filename: str = "image.jpg", 
                                     languages: str = "ru,en") -> Dict[str, Any]:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ llm-svc"""
    
    async def _async_recognize():
        service = await get_llm_service()
        return await service.recognize_text_from_image(image_file, filename, languages)
    
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(asyncio.run, _async_recognize())
                return future.result()
        else:
            return loop.run_until_complete(_async_recognize())
    except RuntimeError:
        return asyncio.run(_async_recognize())
