# ===========================================
# MemoAI Project - Environment Variables
# ===========================================
# Скопируйте этот файл в .env и настройте под ваше окружение
# cp env.example .env

# ===========================================
# ОСНОВНЫЕ НАСТРОЙКИ ПРОЕКТА
# ===========================================

# Режим работы (development, production, testing)
NODE_ENV=development
PYTHON_ENV=development

# Отладочный режим
DEBUG=true
LOG_LEVEL=INFO

# ===========================================
# НАСТРОЙКИ СЕРВИСОВ
# ===========================================

# Backend (MemoAI Backend)
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
BACKEND_WORKERS=1

# Frontend (React)
FRONTEND_HOST=0.0.0.0
FRONTEND_PORT=3000
REACT_APP_API_URL=http://localhost:8000
REACT_APP_WS_URL=ws://localhost:8000

# LLM Service (AI Models Service)
LLM_SVC_HOST=0.0.0.0
LLM_SVC_PORT=8001
LLM_SVC_INTERNAL_URL=http://llm-svc:8000
LLM_SVC_EXTERNAL_URL=http://localhost:8001

# ===========================================
# ПУТИ К МОДЕЛЯМ (настраиваемые)
# ===========================================

# LLM модели (большие языковые модели)
LLM_MODEL_PATH=/app/models/Qwen3-Coder-30B-A3B-Instruct-Q8_0.gguf
LLM_MODEL_NAME=qwen-coder-30b
LLM_MODEL_CTX_SIZE=4096
LLM_MODEL_GPU_LAYERS=0

# Vosk модели (речевое распознавание)
VOSK_MODEL_PATH=/app/models/vosk-model-small-ru-0.22

# Silero модели (синтез речи)
SILERO_MODELS_DIR=/app/models/silero

# WhisperX модели (продвинутое распознавание)
WHISPERX_MODELS_DIR=/app/models/whisperx

# Модели диаризации (разделение по спикерам)
DIARIZATION_MODELS_DIR=/app/models/diarization
DIARIZATION_CONFIG_PATH=/app/models/diarization/pyannote_diarization_config.yaml

# ===========================================
# ПРИМЕРЫ ДЛЯ РАЗНЫХ ОКРУЖЕНИЙ
# ===========================================

# ЛОКАЛЬНАЯ РАЗРАБОТКА (модели в Docker volumes)
# LLM_MODEL_PATH=/app/models/Qwen3-Coder-30B-A3B-Instruct-Q8_0.gguf
# VOSK_MODEL_PATH=/app/models/vosk-model-small-ru-0.22
# SILERO_MODELS_DIR=/app/models/silero
# WHISPERX_MODELS_DIR=/app/models/whisperx
# DIARIZATION_MODELS_DIR=/app/models/diarization

# ОБЛАЧНОЕ ХРАНИЛИЩЕ (S3, MinIO, Google Cloud Storage)
# LLM_MODEL_PATH=s3://my-bucket/models/Qwen3-Coder-30B-A3B-Instruct-Q8_0.gguf
# VOSK_MODEL_PATH=s3://my-bucket/models/vosk-model-small-ru-0.22
# SILERO_MODELS_DIR=s3://my-bucket/models/silero
# WHISPERX_MODELS_DIR=s3://my-bucket/models/whisperx
# DIARIZATION_MODELS_DIR=s3://my-bucket/models/diarization

# HTTP/HTTPS URL (скачивание моделей)
# LLM_MODEL_PATH=https://huggingface.co/microsoft/DialoGPT-medium/resolve/main/pytorch_model.bin
# VOSK_MODEL_PATH=https://alphacephei.com/vosk/models/vosk-model-small-ru-0.22
# SILERO_MODELS_DIR=https://models.silero.ai/models/tts/ru
# WHISPERX_MODELS_DIR=https://huggingface.co/whisperx/models
# DIARIZATION_MODELS_DIR=https://huggingface.co/pyannote/models

# ЛОКАЛЬНАЯ ФАЙЛОВАЯ СИСТЕМА
# LLM_MODEL_PATH=/home/user/models/Qwen3-Coder-30B-A3B-Instruct-Q8_0.gguf
# VOSK_MODEL_PATH=/home/user/models/vosk-model-small-ru-0.22
# SILERO_MODELS_DIR=/home/user/models/silero
# WHISPERX_MODELS_DIR=/home/user/models/whisperx
# DIARIZATION_MODELS_DIR=/home/user/models/diarization

# ===========================================
# НАСТРОЙКИ LLM СЕРВИСА
# ===========================================

# Генерация текста
LLM_DEFAULT_TEMPERATURE=0.7
LLM_DEFAULT_MAX_TOKENS=1024
LLM_STREAM=true

# Устройство для вычислений
CUDA_VISIBLE_DEVICES=0
DEVICE=auto  # auto, cpu, cuda

# WhisperX настройки
WHISPERX_DEVICE=auto
WHISPERX_COMPUTE_TYPE=float16
WHISPERX_LANGUAGE=ru
WHISPERX_BATCH_SIZE=16

# Диаризация настройки
DIARIZATION_DEVICE=auto
DIARIZATION_MIN_SPEAKERS=1
DIARIZATION_MAX_SPEAKERS=10
DIARIZATION_MIN_DURATION=1.0

# ===========================================
# НАСТРОЙКИ BACKEND
# ===========================================

# Микросервисы
USE_LLM_SVC=true
DOCKER_ENV=true
CONFIG_PATH=/app/config/config.yml

# Таймауты и повторы
LLM_SVC_TIMEOUT=300
LLM_SVC_RETRY_ATTEMPTS=3
LLM_SVC_RETRY_DELAY=1

# Память и кэширование
MEMORY_ENABLED=true
MEMORY_STORAGE_TYPE=file
MEMORY_FILE_PATH=/app/memory
MEMORY_MAX_HISTORY_LENGTH=100
MEMORY_AUTO_SAVE=true
MEMORY_SAVE_INTERVAL=30

# Кэширование
CACHING_ENABLED=true
CACHING_TYPE=memory
CACHING_TTL=300
CACHING_MAX_SIZE=1000

# ===========================================
# НАСТРОЙКИ CORS
# ===========================================

# Разрешенные источники (через запятую)
CORS_ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8000,http://127.0.0.1:3000,http://127.0.0.1:8000
CORS_ALLOW_CREDENTIALS=true
CORS_ALLOW_METHODS=*
CORS_ALLOW_HEADERS=*

# ===========================================
# НАСТРОЙКИ БЕЗОПАСНОСТИ
# ===========================================

# API ключи
API_KEY=your-secret-api-key-here
ENABLE_SECURITY=false  # true для продакшена

# Rate limiting
RATE_LIMITING_ENABLED=false
RATE_LIMITING_REQUESTS_PER_MINUTE=60

# ===========================================
# НАСТРОЙКИ ФАЙЛОВ
# ===========================================

# Загрузка файлов
UPLOAD_DIR=/app/uploads
MAX_FILE_SIZE=104857600  # 100MB
TEMP_DIR=/tmp/memoai

# Разрешенные расширения (через запятую)
ALLOWED_EXTENSIONS=.txt,.md,.pdf,.docx,.wav,.mp3,.mp4,.m4a,.flac,.ogg

# ===========================================
# НАСТРОЙКИ ЛОГИРОВАНИЯ
# ===========================================

# Общие настройки
LOG_LEVEL=INFO
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s
LOG_CONSOLE=true

# Файлы логов
LOG_FILE_BACKEND=/app/logs/backend.log
LOG_FILE_LLM_SVC=/app/logs/llm-svc.log
LOG_MAX_SIZE=10485760  # 10MB
LOG_BACKUP_COUNT=5

# ===========================================
# НАСТРОЙКИ МОНИТОРИНГА
# ===========================================

# Health checks
HEALTH_CHECK_ENABLED=true
HEALTH_CHECK_INTERVAL=30

# Метрики
METRICS_ENABLED=false
PROMETHEUS_PORT=9090
PROMETHEUS_PATH=/metrics

# ===========================================
# НАСТРОЙКИ WEBSOCKET
# ===========================================

# WebSocket соединения
WEBSOCKET_ENABLED=true
WEBSOCKET_PING_INTERVAL=30
WEBSOCKET_PING_TIMEOUT=10
WEBSOCKET_MAX_CONNECTIONS=100

# ===========================================
# НАСТРОЙКИ АГЕНТОВ
# ===========================================

# Агенты
AGENTS_ENABLED=true
DEFAULT_AGENT=general
ORCHESTRATOR_ENABLED=true
ORCHESTRATOR_MAX_ITERATIONS=10
ORCHESTRATOR_TIMEOUT=60
ORCHESTRATOR_PARALLEL_EXECUTION=false

# Доступные агенты (через запятую)
AVAILABLE_AGENTS=general,calculation,document,web_search,memory,mcp

# ===========================================
# НАСТРОЙКИ ИНСТРУМЕНТОВ
# ===========================================

# Инструменты
TOOLS_ENABLED=true

# Доступные инструменты (через запятую)
AVAILABLE_TOOLS=calculator,web_search,file_operations,memory_operations,mcp_tools

# ===========================================
# НАСТРОЙКИ РАЗРАБОТКИ
# ===========================================

# Hot reload
HOT_RELOAD=true
DEBUG_TOOLBAR=false
PROFILING=false
MOCK_LLM=false

# ===========================================
# НАСТРОЙКИ БАЗЫ ДАННЫХ (если используется)
# ===========================================

# PostgreSQL
# DATABASE_URL=postgresql://user:password@localhost:5432/memoai
# DATABASE_HOST=localhost
# DATABASE_PORT=5432
# DATABASE_NAME=memoai
# DATABASE_USER=user
# DATABASE_PASSWORD=password

# Redis (если используется)
# REDIS_URL=redis://localhost:6379/0
# REDIS_HOST=localhost
# REDIS_PORT=6379
# REDIS_DB=0

# ===========================================
# НАСТРОЙКИ ВНЕШНИХ СЕРВИСОВ
# ===========================================

# Hugging Face
# HUGGINGFACE_API_TOKEN=your-huggingface-token

# OpenAI (если используется)
# OPENAI_API_KEY=your-openai-key

# Google Cloud (если используется)
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json

# AWS (если используется)
# AWS_ACCESS_KEY_ID=your-access-key
# AWS_SECRET_ACCESS_KEY=your-secret-key
# AWS_DEFAULT_REGION=us-east-1

# ===========================================
# ПРИМЕРЫ КОМАНД
# ===========================================

# Запуск в режиме разработки:
# docker-compose up

# Запуск в продакшене:
# docker-compose -f docker-compose.prod.yml up

# Запуск только backend:
# docker-compose up memoai-backend

# Запуск только llm-svc:
# docker-compose up llm-svc

# Просмотр логов:
# docker-compose logs -f llm-svc
# docker-compose logs -f memoai-backend

# ===========================================
# ПРИМЕЧАНИЯ
# ===========================================

# 1. Все пути к моделям можно задавать как локальные, так и удаленные (S3, HTTP)
# 2. Переменные окружения имеют приоритет над значениями в конфигурационных файлах
# 3. Для продакшена обязательно установите ENABLE_SECURITY=true и задайте API_KEY
# 4. Размеры файлов указываются в байтах (104857600 = 100MB)
# 5. Временные интервалы указываются в секундах
# 6. Списки значений разделяются запятыми без пробелов
